/*
// CH09: DETAILS

So far, we have a working API, but it's lacking the finishing 
touches that will allows us to put it into production. In this
chapter we'll implement some web and GraphQL application security
and user experience best practices. These details will be critical to 
safety, security, and usability of our application.

// WEB APPLICATION AND EXPRESS.JS BEST PRAX...

Express.js is the underlying web application framework that 
powers our API. We can make a few small tweaks to our Express.js
code to provide a solid basis for our application.

// EXPRESS HELMET

The 'Express Helmet' middleware...:
https://github.com/helmetjs/helmet

... is a collection of small security-minded middleware functions.
These will adjust our application's HTTP headers to be more secure.
While many of these are specific to browser-based applications, 
enabling Helmet is a simple step to protect our application from 
common web vulnerabilities. 

To enable 'Helmet', we'll require the middleware in our application 
and instruct Express ot use it early in our middleware stack. In the 
'/src/index.js' file, add the following:

```
// first require the package at the top of the file
const helmet = require('helmet')

// add the middleware at the top of the stack, after `const app = express()`
app.use(helmet());
```

By adding the 'Helmet' middleware, we're quickly enabling common
web security best practices for our application.

// CROSS-ORIGIN RESOURCE SHARING

Cross-Origin Resource Sharing (CORS) is the means by which we allow
resources to be requested from another domain.  Because our API and
UI code will live separately, we'll want to enable credentials from
other origins. If you're interested in learing the ins and outs of 
'CORS', teach highly recommends the 'Mozilla CORS guide'...:
https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS

... To enable CORS, we'll use the Express.js CORS middleware...:
https://expressjs.com/en/resources/middleware/cors.html

... we'll use the Express.js middleweare and add it ot our
'/src/index.js';

```
// first require teh package at the top of the file
const cors = require('cors');

// add the middleware after app.use(helmet());
app.use(cors());
```

By adding the middleware in this way, we are enabling cross-origin
requests from _all_ domains. This works well for us for now, as we're
in development mode and will likely be using domains generated by our 
hosting providers, but y using the middleware, we could also limit 
the requests to those of specific origins!s

// PAGINATION

Currently, our `notes` and `user` queries return the full list
of notes and users in the database. This works fine for local
development, but as our application grows it will become 
unsustainaable, as a query that returns potentially hundreds 
(or thousands) of notes is expensive and will slow down our 
database, server, and netowrk. Instead, we can paginate those 
queries, returning only a set number of results.

There are 2 common types of pagination that we could implement:

1. OFFSET PAGINATION:
The first type, _offset pagination__, works by the client passing
an offset number and returning a limited amount of data. For 
example, if each page of data were limited to 10 records, and we
wanted to request the thired page of data, we could pass an 
offset of 20. While this is the most straightforward approach,
conceptually, it can run into scaling and performing issues. 

2. CURSOR-BASED PAGINATION:

The second type, _cursor-based pagination_, in which a time-based
cursor or unique identifier is passed a a starting point. We then
request a specific amount of data that follows this record. This
approach gives us the greatest control over our pagination. 
Additionally, because Mongo's object IDs are ordered (they begin with
4-byte time value), we can easily utilize them as our cursor. To
learn more about Mongo's object ID, reach recommends reading the 
corresponding MongoDB docs:
https://www.mongodb.com/docs/manual/reference/method/ObjectId/

Let's walk through implementing a paginated feed of notes as a 
GraphQL query. First, let's define what we'll be creating, folowed
by our schema updates, and lastly our resolver code. For our feed,
we'll want to query our API while optionally passing a cursor as a
parameter. The API should then return a limited amount of data, 
a cursor point representing the last item in the data set, and a 
Boolean value if there is an additional page of data to query. 

With this description, we can update our '/src/schema.js' file 
to define this new query. First, we'll need to add a `NoteFeed`
type to our file:

```
type NoteFeed {
    notes: [Note]!
    cursor: String!
    hasNextPage: Boolean!
}
```

Next, we add our `noteFeed` query:

```
type Query {
    # add `noteFeed` to our existing queries
    noteFeed(cursor: String): NoteFeed
}
```

With our schema updated, we can write the resolver code for our
query. In '/src/resolvers/query.js', add the following to the 
exported object:

```
noteFeed: async (parent, { cursor } , { models }) => {
    // hardcode the limit to 10 items
    const limit = 10;
    
    // set the default hasNextPage value to false
    let hasNextPage = false;
    
    // if no cursor is passed the default query will be empty
    // this will pull the newest notes from the db
    let cursorQuery = {};

    // if there is a cursor
    // our query will look for notes with an ObjectId less than that 
    // of the cursor
    if (cursor) {
        cursorQuery = { _id: { $lt: cursor } };
    }

    // find the `limit + 1` of `notes` in our `db`, sorted newest to oldest
    let notes = await models.Note.find(cursorQuery)
        .sort({_id: -1})
        .limit(limit + 1);

    // if the number of notes we find exceeds our limit
    // set hasNextPage to true and trim the notes to the limit
    if (notes.length) > limit) {
        hasNextPage = true;
        notes = notes.slice(0, -1)
    }

    // the new cursor will be the Mongo object ID of the last item in the feed array
    const newCursor = notes[notes.length - 1]._id;

    return {
        notes,
        cursor: newCursor
        hasNextPage
    };
}
```

OK we were able to update our '/src/resolvers/query.js' file!

With this resolver in place, one can now query our `noteFeed`, which
will return a maximum of 10 results. In the GP, we can write a query
as follows to receive a list of notes, their object IDs, their 
`createdAt` timestamps, the cursor, and `hasNextPage` boolean:

```
query {
    noteFeed {
        notes {
            id
            createdAt
        }
        cursor
        hasNextPage
    }
}
```

this gave us the following output:

```
{
  "data": {
    "noteFeed": {
      "notes": [
        {
          "id": "62ba50d21fea342ac0fd73c1",
          "createdAt": "2022-06-28T00:52:34.513Z"
        },
        {
          "id": "62ad64e8ab1a9232047c7a38",
          "createdAt": "2022-06-18T05:38:48.443Z"
        },
        {
          "id": "62915f9a65b436024c8daaa2",
          "createdAt": "2022-05-27T23:32:42.264Z"
        },
        {
          "id": "628d75728a694b2c3891e7ae",
          "createdAt": "2022-05-25T00:16:50.763Z"
        },
        {
          "id": "6280057a77cc7522a47ab48e",
          "createdAt": "2022-05-14T19:39:38.821Z"
        }
      ],
      "cursor": "6280057a77cc7522a47ab48e",
      "hasNextPage": false
    }
  }
}
```

made 10 more notes, test noteFeed with limit > 10 tomorrow!

now that we have more than 10 notes, the call to our `noteFeed` query
returned the last 10 notes we created:

```
{
  "data": {
    "noteFeed": {
      "notes": [
        {
          "id": "62cf6054f669b20668f7e0d5",
          "createdAt": "2022-07-14T00:16:20.835Z",
          "content": "This is an new note 10"
        },
        {
          "id": "62cf604ff669b20668f7e0d4",
          "createdAt": "2022-07-14T00:16:15.089Z",
          "content": "This is an new note 9"
        },
        {
          "id": "62cf6048f669b20668f7e0d3",
          "createdAt": "2022-07-14T00:16:08.896Z",
          "content": "This is an new note 8"
        },
        {
          "id": "62cf6042f669b20668f7e0d2",
          "createdAt": "2022-07-14T00:16:02.659Z",
          "content": "This is an new note 7"
        },
        {
          "id": "62cf603bf669b20668f7e0d1",
          "createdAt": "2022-07-14T00:15:55.999Z",
          "content": "This is an new note 6"
        },
        {
          "id": "62cf6035f669b20668f7e0d0",
          "createdAt": "2022-07-14T00:15:49.103Z",
          "content": "This is an new note 5"
        },
        {
          "id": "62cf5ffaf669b20668f7e0cf",
          "createdAt": "2022-07-14T00:14:50.759Z",
          "content": "This is an new note 4"
        },
        {
          "id": "62cf5feff669b20668f7e0ce",
          "createdAt": "2022-07-14T00:14:39.192Z",
          "content": "This is an new note 3"
        },
        {
          "id": "62cf5fe5f669b20668f7e0cd",
          "createdAt": "2022-07-14T00:14:29.184Z",
          "content": "This is an new note 2"
        },
        {
          "id": "62cf5fbbf669b20668f7e0cc",
          "createdAt": "2022-07-14T00:13:47.324Z",
          "content": "This is an new note"
        }
      ],
      "cursor": "62cf5fbbf669b20668f7e0cc",
      "hasNextPage": true
    }
  }
}
```

Since we have a more than 10 notes in our database, this returns
a cursor as well as a hasNextPage value of true. With that cursor,
we can query the second page of the feed:

```
query {
    noteFeed(cursor: "62cf5fbbf669b20668f7e0cc") {
        notes {
            id
            createdAt
            content
            author {
              username
            }
        }
        cursor
        hasNextPage
    }
}
```

this returned the older notes that existed before
the most recent 10 that were created:

```
{
  "data": {
    "noteFeed": {
      "notes": [
        {
          "id": "62ba50d21fea342ac0fd73c1",
          "createdAt": "2022-06-28T00:52:34.513Z",
          "content": "New note to test toggleFavorite resolver!"
        },
        {
          "id": "62ad64e8ab1a9232047c7a38",
          "createdAt": "2022-06-18T05:38:48.443Z",
          "content": "Hello! This is a user-created note!"
        },
        {
          "id": "62915f9a65b436024c8daaa2",
          "createdAt": "2022-05-27T23:32:42.264Z",
          "content": "This is the updated note to test updatedAt!"
        },
        {
          "id": "628d75728a694b2c3891e7ae",
          "createdAt": "2022-05-25T00:16:50.763Z",
          "content": "This is the updated note!"
        },
        {
          "id": "6280057a77cc7522a47ab48e",
          "createdAt": "2022-05-14T19:39:38.821Z",
          "content": "This is a note in our database!"
        }
      ],
      "cursor": "6280057a77cc7522a47ab48e",
      "hasNextPage": false
    }
  }
}
```

We can continue to do this for each cursor where the
hasNextPage value is `true`. With this implementation
in place, we've created a paginated feed of notes. This
will both allow our UI to request a specific feed of data,
as well as reduce the burden on our server and database!

just to test teh nested query functionality, we made the
following query:

```
query {
    noteFeed {
        notes {
            id
            createdAt
            content
          	author {
              id
              username
            }
        }
        cursor
        hasNextPage
    }
}
```

which returned the following:

```
{
  "data": {
    "noteFeed": {
      "notes": [
        {
          "id": "62cf6054f669b20668f7e0d5",
          "createdAt": "2022-07-14T00:16:20.835Z",
          "content": "This is an new note 10",
          "author": {
            "id": "62a139c7f3fb9e250c1029be",
            "username": "BeeBoop4"
          }
        },
        {
          "id": "62cf604ff669b20668f7e0d4",
          "createdAt": "2022-07-14T00:16:15.089Z",
          "content": "This is an new note 9",
          "author": {
            "id": "62a139c7f3fb9e250c1029be",
            "username": "BeeBoop4"
          }
        },
        {
          "id": "62cf6048f669b20668f7e0d3",
          "createdAt": "2022-07-14T00:16:08.896Z",
          "content": "This is an new note 8",
          "author": {
            "id": "62a139c7f3fb9e250c1029be",
            "username": "BeeBoop4"
          }
        },
        {
          "id": "62cf6042f669b20668f7e0d2",
          "createdAt": "2022-07-14T00:16:02.659Z",
          "content": "This is an new note 7",
          "author": {
            "id": "62a139c7f3fb9e250c1029be",
            "username": "BeeBoop4"
          }
        },
        {
          "id": "62cf603bf669b20668f7e0d1",
          "createdAt": "2022-07-14T00:15:55.999Z",
          "content": "This is an new note 6",
          "author": {
            "id": "62a139c7f3fb9e250c1029be",
            "username": "BeeBoop4"
          }
        },
        {
          "id": "62cf6035f669b20668f7e0d0",
          "createdAt": "2022-07-14T00:15:49.103Z",
          "content": "This is an new note 5",
          "author": {
            "id": "62a139c7f3fb9e250c1029be",
            "username": "BeeBoop4"
          }
        },
        {
          "id": "62cf5ffaf669b20668f7e0cf",
          "createdAt": "2022-07-14T00:14:50.759Z",
          "content": "This is an new note 4",
          "author": {
            "id": "62a139c7f3fb9e250c1029be",
            "username": "BeeBoop4"
          }
        },
        {
          "id": "62cf5feff669b20668f7e0ce",
          "createdAt": "2022-07-14T00:14:39.192Z",
          "content": "This is an new note 3",
          "author": {
            "id": "62a139c7f3fb9e250c1029be",
            "username": "BeeBoop4"
          }
        },
        {
          "id": "62cf5fe5f669b20668f7e0cd",
          "createdAt": "2022-07-14T00:14:29.184Z",
          "content": "This is an new note 2",
          "author": {
            "id": "62a139c7f3fb9e250c1029be",
            "username": "BeeBoop4"
          }
        },
        {
          "id": "62cf5fbbf669b20668f7e0cc",
          "createdAt": "2022-07-14T00:13:47.324Z",
          "content": "This is an new note",
          "author": {
            "id": "62a139c7f3fb9e250c1029be",
            "username": "BeeBoop4"
          }
        }
      ],
      "cursor": "62cf5fbbf669b20668f7e0cc",
      "hasNextPage": true
    }
  }
}
```

// DATA LIMITATIONS

In addition to establishing pagination, we'll want to limit 
the amount of data that can be requested through our API. This
prevents queries that could overlaod our server or database!

A simple first step in this process is to limit the amount of
data that a query can return. Two of our queries, `users` and 
`notes`, return all of the matching data from the database. We
could address this by setting a `limit` method on our database
queries.

For example, in our '/src/resolvers.query.js' file, we can
update our `notes` query as follows:

```
notes: async (parent, args, { models}) => {
  return await models.Note.find().limit(100);
}
```

While limiting dat is a solid start, currently our queries can
be written with an unlimited depth. This means that a single 
query could be written to retrieve a list of notes, the author
informaiton for each of those notes, the list of favorites of 
each author, the author informaiton for each of those favorites,
and so on.

That's a lot of data in one query, and we could keep going! To
prevent these types of overnested queries, we can _limit
the depth_ of qeuries against our API.

Additionally, we might have complex queries that are not overly
nested, but still require heavy computation to return the data.
We can protect against these types of requests by _limiting
query complexity_.

We can implement these limits by using the `graphql-depth-limit`
and `graphql-validation-complexity` packages in our application.
To take advantage of these packages' functionality, we can 
update our '/src/index.js' file as follows:

```
// import the modules at the top of the file
const depthlimit = require('graphql-depth-limit');
const { createComplexityLimitRule } = require('graphql-validation-complexity); 

// update our ApolloServer code to include validationRules
const server = new ApolloServer({
  typeDefs,
  resolvers,
  validationRules: [depthLimit(5), createComplexityLimitRule(1000)],
  context: async({ req }) => {
    // get the user token from the headers
    const token = req.headers.authorization;
    // try to retrieve a user with the token
    const user = await gtUser(token);
    // add the db models and the user to the context
    return { models, user };
  }
});
```

With these package additions, we've added extra query
protection to our API. For more informaiton, on securing
a GraphQL API from malicious queries, check out the
fantastic article:

https://oreil.ly/_r5tl) from Max Stoiber, CTO of Spectrum.

// OTHER CONSIDERATIONS

After building our API, one should have a solid understanding of 
the fundamentals of GraphQL development. If one is eager to dig in
more on the topics, some excellent places to go next would be
testing. GraphQL subscriptions an Apollo Engine.

// TESTING

Testing code is important because it allows us to comfortably 
make changes and improves our collaboration with other devs. 
One of the great things about our GraphQL setups is that
resolvers are simply functions, taking some parameters and
returning data. This makes our GraphQL logic straightforward
to test.

// SUBSCRIPTIONS

Subscriptions are an incredibly powerful feature of GraphQL, which
offers a straightforward way to integrate the publish-subscribe
pattern in our application. This means that a UI can subscribe to
be notified or updated when data is published on the server. This 
makes GraphQL servers an ideal solution for applications that work
with real-time data. For more information about GraphQL 
subscriptions, teach recs looking at the Apollo Server 
documentation:
https://www.apollographql.com/docs/apollo-server/

// APOLLO GRAPHQL PLATFORM

Throughout the development of our API, teach has been using
the Apollo GraphQL library. In future chapters, we'll be using the 
Apollo client librariesto interface with our API. Teach has chosen 
these libraries because they are industry standards and offer
a great developer experience for working with GraphQL. If one 
takes one's application to production, Apollo, the company who 
maintains these libraries, also offers a platform that provides 
monitoring and tooling for GraphQL APIs. One can learn mor at 
Apollo's website!

// CONCLUSION

In this chapter we added some finishing touches to our
application. Though there are many other options we could
implement, at this point we have developed a solid 
MVP (minimal viable product). In this state, we are 
ready to lauch our API! 

In the next chapter, we deploy our API to a public
web server!



*/